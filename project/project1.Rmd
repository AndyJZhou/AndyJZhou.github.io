---
title: "Comp Bio Project 1"
author: "Andy Zhou, ajz476"
date: '2020-10-18'
output:
  html_document:
    toc: true
    toc_float:
      collapsed: True
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```

```{r}
library(tidyverse)
library(cluster)
library(GGally)
```

### Introduction

The two datasets I have chosen are data local to my area (Bexar County) relating to the COVID-19 pandemic. The first dataset is COVID-19 data from San Antonio from February to September documenting information for cases, deaths, hospitalizations and ventilators. The second dataset pertains to the weather in San Antonio for that same time period. The weather measurements were collected from a weather station at San Antonio International Airport. I am taking them to be representative of the county for the purposes of this project. The weather measurements include information about temperature, precipitation, and wind. With speculation about the potential behavior of the coronavirus in different climate conditions, I wanted to perform this exploratory data analysis to see if I could find any interesting associations. Temperature was a factor that many scientists have speculated may have an effect on the ease of spread of the coronavirus and that is an association that I will look for.

Full documentation for weather data: https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf  

COVID-19 Data documentation: https://cosacovid-cosagis.hub.arcgis.com/datasets/samhd-daily-surveillance-data-public?selectedAttribute=strac_available_staffed_beds&showData=true  
*Note: STRAC is simply the acronym for the regional governmental heath authority that collected this data*



### Importing Datasets

```{r}
tempData <- read.csv("2296372.csv")
tempData %>% head

covData <- read.csv("SAMHD_Daily_Surveillance_Data_Public.csv")
covData %>% tail
```

#### Remove Unwanted Variables from Datasets

```{r}
# Make some custom functions
# Counts the number of NA's for a variabe
countNAs <- function(x){
  sum(is.na(x))
}

# Reports the proportion of NA's for a variable
propNAs <- function(x){
  mean(is.na(x))
}

# Filter out variables with too many na's
covData <- covData %>% select_if(~propNAs(.) < 0.5)
tempData <- tempData %>% select_if(~propNAs(.) < 0.5)
```
These custom functions help me filter out variables that are comprised of 50% or more NA's.

#### Clean Up Columns Before Join

```{r}
covData <- covData %>% separate(reporting_date,into=c("reporting_date","TIME"),sep=" ") %>% select(-TIME)%>% 
  mutate(reporting_date=str_trim(reporting_date)) %>% mutate(objectid=as.character(objectid)) %>% mutate(day_number=seq(1:nrow(covData)))

tempData <- tempData %>% mutate(DATE = str_replace_all(DATE, "-","/")) %>% mutate(DATE = str_trim(DATE)) %>% select(-contains(c("attributes","WT"))) %>% select(-(1:5))
```
This puts the two date variables that I will be joining by into the same format so that the join will be successful. 

### Joining/Merging

I joined my two variables by date, as each observation is either dataset represented the data collected for a single day. I used a `left_join` with the COVID-19 data to ensure it is preserved because the information in that dataset is more valuable to my exploratory data analysis than the weather data. The weather data is more of a supplementary dataset to add extra information to the COVID-19 data that I am really interested in. There were `r nrow(covData)` observations in `covData` and `r nrow(tempData)` observations in `tempData`.
`r abs(nrow(covData)-nrow(tempData))` days were lost from `tempData` after the join, but that's because it had more days than `covData` which is not a significant issue. After joining, I also separate the date variable that I joined by to into individual variables that will help with my analysis later. Then I clean up the dataset by removing all NA's.


```{r}
# Join Datasets
covData <- covData %>% left_join(tempData, by = c("reporting_date"="DATE"))
covData <- covData %>% separate(reporting_date, into = c("Year", "Month", "Day"),convert = T)
```

```{r}
# Remove NA's
before <- nrow(covData)
covData <- covData %>% na.omit()
covData %>% head
after <- nrow(covData)
```
After removing NA's, I lost `r abs(before-after)` rows, which is a significant amount. However, upon a closer look, the majority of the rows were in the beginning of the dataset. My dataset originally started in February but after removing NA's it starts in April. This is due to the fact that early on in the pandemic, data for many of the variables in the dataset was not collected. Thus, February and March don't have detailed information for most of the variables. This is an artifact of the initial pandemic response. The loss is unfortunate but should not affect my exploratory analysis is a major way. It just reduced the time period I have data for.  

### Wrangling and Tidying: Rearranging Wide/Long


To put my summary statistics in prettier tables, I calculated the statistics, then used `pivot_longer` to display them in an easy to read way.



### Summary Statistics
#### Average
```{r}
average <- covData %>% summarize_if(is.numeric,mean) %>% pivot_longer(everything(),names_to = "Measure", values_to = "Average") %>% mutate(Average=round(Average)) %>% arrange(desc(Average))
average
```
Some notable results to point out:  
The average daily change in cases was `r average %>% filter(Measure == "total_case_daily_change") %>% select(Average) %>% round` cases.  
The average daily change in deaths was `r average %>% filter(Measure == "deaths_daily_change") %>% select(Average) %>% round` deaths.  
The average daily wind speed was `r average %>% filter(Measure == "AWND") %>% select(Average) %>% round` mph.  
We can see that over this period, there were a lot of new cases as shown by the large daily average. Contrast this with the relatively smaller average daily change in death. We can see that most people who were infected do not die. There was also a decent amount of wind over this period, which is unlikely to have been a contributing factor in the spread of the virus, but may be interesting to consider,especially with new evidence of it's airborne transmission. 

#### Standard Deviation
```{r}
standard_deviation <- covData %>% summarize_if(is.numeric,sd) %>% pivot_longer(everything(),names_to = "Measure", values_to = "Standard_Deviation") %>% mutate(Standard_Deviation=round(Standard_Deviation)) %>% arrange(desc(Standard_Deviation))
standard_deviation
```
Some notable results to point out:  
The standard deviation of total staffed beds was `r standard_deviation %>% filter(Measure == "strac_total_staffed_beds") %>% select(Standard_Deviation) %>% round` beds.  
The standard deviation of available ventilators was `r standard_deviation %>% filter(Measure == "strac_available_ventilators") %>% select(Standard_Deviation) %>% round` ventilators.  
The standard deviation of total ventilators was `r standard_deviation %>% filter(Measure == "strac_total_ventilators") %>% select(Standard_Deviation) %>% round` ventilators.

This provides a measure of the spread of values for each variable, giving us an idea of how much these indicators changed during the course of the pandemic. We can see that there was a fairly high amount of traffic in and out of hospital beds. This may be good or bad depending on why the patient was moved out of the bed. We can also see that there was a fair amount of fluctuation in the usage of ventilators, implying that the number of critical cases fluctuated during this period as well. Interestingly, there is also some standard deviation of the total amount of ventilators. A dive into the data suggests that this is due to the addition of a large number of new ventilators during this period, documenting the addition of supplies during the county's coronavirus response.

#### Max
```{r}
Max <- covData %>% summarize_if(is.numeric,max) %>% pivot_longer(everything(),names_to = "Measure", values_to = "Maximum_Value") %>% arrange(desc(Maximum_Value))
Max
```
Some notable results to point out:  
The maximum value of total cases was `r as.integer(Max %>% filter(Measure == "total_case_cumulative") %>% select(Maximum_Value) %>% round)` cases.    
The maximum value of daily case change was `r Max %>% filter(Measure == "total_case_daily_change") %>% select(Maximum_Value) %>% round` cases.    
The maximum value of total deaths was `r Max %>% filter(Measure == "deaths_cumulative") %>% select(Maximum_Value) %>% round` deaths.

From the high maximum total case we can see the toll of the pandemic at the time this data was collected in mid-September. We can also see the single worse day in the pandemic in terms of new cases for Bexar County. It should be noted that there was one day where backlogged cases had been entered and thus this max value may reflect that data idiosyncrasy and not a real daily case change count. We can also see the death toll the virus has taken on the community with the total deaths at the time of the data collection. These metrics show that COVID-19 is no joke and that we should all take health recommendations seriously. 

#### Min
```{r}
Min <- covData %>% summarize_if(is.numeric,min) %>% pivot_longer(everything(),names_to = "Measure", values_to = "Minimum_Value") %>% arrange(Minimum_Value) %>% filter(`Minimum_Value`>0)
Min
```
Some notable results to point out:  
The lowest number of positive cases in the ICU was `r Min %>% filter(Measure == "strac_covid_positive_in_icu") %>% select(Minimum_Value) %>% round` cases.  
The lowest number of available staffed beds was `r Min %>% filter(Measure == "strac_available_staffed_beds") %>% select(Minimum_Value) %>% round` beds.  
The lowest average temperature was `r Min %>% filter(Measure == "TAVG") %>% select(Minimum_Value) %>% round` degrees Fahrenheit.  

The min data shows some interesting information. The min ICU positive cases shows that the virus was not wreaking maximum devastation during the entire `r covData %>% select(Month) %>% n_distinct`-month period. It seems that there were times of calmness in the pandemic. Contrast that with minimum number of available beds and we see that there were certainly days where it may have felt that the pandemic was overwhelming. For county-level data, such a low number of available is concerning. On a lighter note, we can also see that during this period there were actually days of colder weather, a bit more enjoyable than the sweltering summer heat. 

#### Distinct
```{r}
Distinct <- covData %>% summarize_if(is.numeric,n_distinct) %>% pivot_longer(everything(),names_to = "Measure", values_to = "Number_of_Distinct_Values") %>% pivot_wider(names_from = "Measure", values_from="Number_of_Distinct_Values") %>% select(PRCP,AWND,strac_total_staffed_beds, everything())
Distinct
```
Some notable results to point out:  
There was `r Distinct %>% select(PRCP) %>% round` distinct values in precipitation.    
There was `r Distinct %>% select(AWND) %>% round` distinct values in average wind speed.  
There was `r Distinct %>% select(strac_total_staffed_beds) %>% round` distinct values in total staffed beds.

The distinct summary statistics tell us information similar to standard deviation. The low number of distinct precipitation values tells us that unsurprisingly, Texas received little rainfall during this period. There are roughly `r covData %>% nrow` data points but only `r Distinct %>% select(PRCP) %>% round` distinct values of precipitation (most of them are 0). The distinct number of wind values tells us that either there was little to no wind most days or that what wind there was was really consistent across this period. And to bring it back to COVID-19 again, we can see that the `r Distinct %>% select(strac_total_staffed_beds) %>% round` distinct values in total staffed beds reveals that there was frequent movement in and out of the beds during this period. 

#### Correlation
```{r}
covData %>% select(-(1:5),-SNOW,-SNWD) %>% cor() %>% as.data.frame %>% head %>% select(1:5)
```
Here's the correlation matrix for all the numeric variables. Discussion will follow after the heat map later on. 

#### Grouping by 1 Categorical Variable
```{r}
# Summary statistic after grouping by above or below average new cases
grp1 <- covData %>% mutate(abovavg=total_case_daily_change>mean(total_case_daily_change)) %>% group_by(abovavg) %>% select_if(is.numeric) %>% summarise_all(sd)
grp1 %>% select(1,strac_available_staffed_beds,5:7)

```
Here is the standard deviation of the numeric variables grouped by whether those days had above average change in daily cases or not.
The usefulness of this display can be seen in this example. Consider the available staffed beds variable. When the new case counts were below average, i.e the virus was not spreading fast, we can see that the standard deviation of available staffed beds was `r grp1 %>%  select(strac_available_staffed_beds) %>% slice(1) %>% round`, as compared to `r grp1 %>%  select(strac_available_staffed_beds) %>% slice(2) %>% round` during the period when the virus was spreading quickly. It's interesting that the standard deviation was higher in the below average period than the above average period. This might be because that there was more variance in the case counts as the virus was picking up and that once it had spread in the community, the daily case change became more consistent. Thus we can more easily understand the effects of the worse days on the pandemic compared to the better days (in terms of new cases) on hospital resources. 

#### Grouping by 2 Categorical Variables
```{r}
# Summary statistic after grouping by by above or below average new cases and month
covData %>% mutate(abovavg=total_case_daily_change>mean(total_case_daily_change)) %>% group_by(Month,abovavg) %>% select_if(is.numeric) %>% summarise_all(sd)
```
Here is that same dataset but now grouped by month.
We can see that April and May had only days where new cases were below average compared to the period overall, while starting in June, there were worse days and better days for each of the subsequent months. This summarizes the virus' initial spread across Bexar County and then subsequent waves as the pandemic dragged on and worsened. Alternatively, this may also be capturing the slow response in implementing testing.  
Note the row of NA's in July, that is due to the fact that there was only a single day that was below average in July, which is why there is no standard deviation data for that category. 

#### New Composite Statistic
```{r}
covData %>% mutate_at(.vars = c("total_case_daily_change","deaths_daily_change","strac_covid_positive_in_hospita","strac_covid_positive_in_icu","strac_covid_positive_on_ventila"),scale) %>% mutate(worst=(total_case_daily_change+deaths_daily_change+strac_covid_positive_in_hospita+strac_covid_positive_in_icu+strac_covid_positive_on_ventila)/5)%>% select(Month,Day,Year,worst) %>% top_n(n = 5,worst) %>% arrange(-worst)
```
This creates a new variable "worst" that is a composite statistic that summarizes/combines: daily case change, daily death change, positive cases in the hospital, positive cases in the ICU, and positive cases on ventilators. It is the average of their z scores for each day and may provide a clearer picture of how "bad" a given day in the pandemic was compared to all days across the period. Shown above are the top 5 "worst" days of the pandemic. 


### Data Visualization

#### 1st Plot
```{r}
# Avg temperature when new cases were above average
covData %>% mutate(`Above Average`=(TAVG>mean(TAVG))) %>% 
  ggplot()+
  geom_histogram(aes(TAVG,total_case_daily_change,fill=`Above Average`),stat = "summary",fun=mean)+
  scale_fill_manual(values = c("blue","red"))+
  xlab("Temperature in Fahrenheit")+
  ylab("Average Number of New Daily Cases")+
  ggtitle("Average New Daily Cases for Days with Above and Below Average Temperatures")+
  scale_y_continuous(breaks=seq(0,900,50))+
  scale_x_binned(breaks = seq(0,max(covData$TAVG),2),)+
  theme(panel.grid.minor=element_blank())
```
This plot shows the the spectrum of temperatures for this time period and the associated average daily change in case count for days with those temperatures. The color indicates if the temperature that day was above or below the average temperature for this period. Note that the individual temperatures on the x-axis are technically average temperatures as well (they come from variable `TAVG`), but they are average temperatures for each individual day as opposed to across the `r covData %>% select(Month) %>% n_distinct` month period.  
We can see that the days with higher new cases also corresponded to days with above average temperatures. This may hint at an association between daily new cases and temperature. It is also important to point out that time may be a confounding variable as the virus appeared in America right as temperatures were getting hotter anyways. 

#### 2nd Plot

```{r}
# Daily change in case total by day and with average temperature
covData %>% mutate(`Average Temperature`=TAVG) %>% ggplot(aes(day_number,total_case_daily_change))+
  geom_point(aes(color = `Average Temperature`),size = 2)+
  scale_color_gradient2(low = "blue", mid = "white", high = "darkred", midpoint = 70)+
  xlab("Day Number Starting at April 1st")+
  ylab("New Cases that Day")+
  ggtitle("Daily Change in Case Total by Day and with Average Temperature in Fahrenheit")+
  scale_y_continuous(breaks=seq(0,6000,500))+
  scale_x_continuous(breaks = seq(0,300,10))+
  theme(panel.grid.minor=element_blank())

```
This plot seeks to track the association between new daily cases and temperature but now across time to see if there really is confounding between variables. We can see that the new cases did rise with time. However, around day 175, we can see declines in new cases as well as temperature as time passes. Thus, this is more evidence of an association between temperature and new cases as they both rise and fall at the same time. Of course, there is the possibility that this is a coincidence as well as this could be the result of states really getting a hold on public health procedures and testing around this time. More data about the specific times policy initiatives were implemented would be needed to rule out time as a confounding variable. 


#### 3rd Plot
```{r}
covData %>% mutate(month2=as.factor(recode(Month,"","","","April","May","June","July","August","September"))) %>% mutate(month2=factor(month2,c("April","May","June","July","August","September"))) %>%
  mutate(`Positive Cases in ICU's`=strac_covid_positive_in_icu) %>% 
  ggplot(aes(`Positive Cases in ICU's`,strac_available_ventilators,color=`Positive Cases in ICU's`))+
  geom_point(size = 2)+
  facet_wrap(~month2,nrow = 3,ncol = 2)+
  scale_color_gradient(low = "orange", high = "darkred")+
  xlab("Positive Cases in ICU's")+
  ylab("Available Ventilators in Hospitals")+
  ggtitle("Relationship between ICU Occupancy and Ventilator Supply per Month")
```
This plot shows the relationship between the number of positive cases in hospital ICU's and the supply of ventilators for each month in this period. The color is redundant but helps with visualizing the story. 
We can see a pretty clear negative correlation between the two variables. This plot also groups by month to make it easier to see the progression of the pandemic during this period. We can see the pandemic build up in April in May, the worst months of June and July, and then see the virus recede in September, likely as a response to state and national health directives, closures etc. This plot helps track the story of the virus as well as show the tangible effects of public health guidelines. This is of course inferred and more data about actual policies put in place during this time would be needed to confirm. 

#### 4th Plot
```{r,fig.width=12, fig.height=12}
# Heatmap
covData %>% select(-(1:5),-SNOW,-SNWD) %>% cor %>% as.data.frame() %>% rownames_to_column("Variable1") %>% pivot_longer(-1,names_to="Variable2",values_to="Correlation") %>% ggplot(aes(Variable1,Variable2,fill=Correlation))+geom_tile()+
scale_fill_gradient2(low="red",mid="white",high="blue")+ #makes colors!
geom_text(aes(label=round(Correlation,2)),color = "black", size = 3)+ #overlays correlation values
theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust = .5))+ #flips the x-axis labels
coord_fixed()+
ggtitle("Correlation Heat map of Numeric Variables")
```
It is interesting from this heat map of the correlation between numeric variables that the temperature variables were more strongly correlated with hospital resources, such as hospital ventilators, than with daily case changes. We see a stronger negative correlation between TMAX, TAVG, and TMIN with available ventilators than a positive one with daily case change. 
We also see barely any correlation between wind variables and any other numeric variable. This may have been due to the fact that wind patterns did not really change that much during this period nor had any impact on the spread of the virus. This data suggests that climate may have less association with the spread of the pandemic than I assumed at the outset of this project. 

### Clusters

#### Choosing k
```{r}
sil_width <- numeric()
for (i in 2:10) {
  pam_fit <- covData %>% select(-(1:5)) %>% select_if(is.numeric) %>% scale %>% pam(k = i)
  sil_width[i] <- pam_fit$silinfo$avg.width
}

ggplot()+
  geom_line(aes(x=1:10, y= sil_width))+scale_x_continuous(name = "k",breaks = 1:10)+
  ylab("Average Silhouette Width")+
  ggtitle("Choosing the Right k")
```
Given this plot of the silhouette width, I chose to use 2 clusters. There was no underlying conceptual or theoretical reasons to choose a specific k for this data so the clustering is truly an exploratory venture to see what interesting groups we can get. 

#### Running PAM and Visualizing
```{r}
cov_pam <- covData %>% select(-(1:5)) %>% select_if(is.numeric) %>% scale %>% pam(k = 2)

plot(cov_pam,which=2)
```
With an average silhouette width of 0.35, the structure in the data is likely to be weak or artificial. This is not surprising given the disparate datasets that I have combined and the fact that there really isn't any theoretical reason why this type of data would naturally cluster. 

```{r,fig.width=30, fig.height=30}
covData %>% mutate(cluster=as.factor(cov_pam$clustering)) %>% 
  ggpairs(columns=c("total_case_daily_change","deaths_daily_change","total_case_cumulative","deaths_cumulative","strac_covid_positive_in_hospita","strac_covid_positive_in_icu","strac_covid_positive_on_ventila","strac_total_ventilators","strac_available_ventilators","day_number"), aes(color=cluster))
```

If you look at the graph comparing cumulative deaths and positive rates you can see the positive rates shoot up before the deaths begin increasing. This shows taht the buildup of cumulative deaths happens in an environment of many positive cases, which makes sense as positive cases preclude death. We see a strong correlation between positive cases in the hospital with positive cases in the ICU, which is not surprising. 

The variable that is the best in almost all cases in defining clusters is day number. From the scatter plots shown, for just about all the variables, the cluster delineates two time periods of different trends. Looking at daily case change and daily death change we see the cluster split the period into a period of low change and a period of more fluctuation. There is also a clear delineation when looking at ventilator supplies, with the two clusters separating a period of more stability and one one of more change. From the density plots, we can see that the distributions of the cluster follow a bimodal distribution. It seems that the clustering algorithm is picking up on the fact that the virus had a calmer period of infection and affliction followed by one that was more severe. This is intuitive to us from our personal experience, but impressive from what is essentially a number cruncher. This may offer support that the numeric variables tracked by public health authorities may be pretty good indicators and provide a good picture of the state of the pandemic. Kudos to the public health experts. 